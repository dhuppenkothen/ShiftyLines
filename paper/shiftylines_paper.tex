% This document is part of the ShiftyLines project.
% Copyright 2016 the authors.

\documentclass[12pt]{emulateapj}
\usepackage{graphicx}
%\usepackage{epsfig}
\usepackage{times}
\usepackage{natbib}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsbsy}
\usepackage{bm}
\usepackage{hyperref}
\usepackage{url}
%\usepackage{subfigure}
\usepackage{microtype}
\usepackage{rotating}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{tabularx}
\usepackage{subfigure}


%\usepackage{longtable}%\usepackage[stable]{footmisc}
%\usepackage{color}
%\bibliographystyle{apj}

\newcommand{\project}[1]{\textsl{#1}}
\newcommand{\fermi}{\project{Fermi}}
\newcommand{\rxte}{\project{RXTE}}
\newcommand{\given}{\,|\,}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\counts}{y}
\newcommand{\pars}{\theta}
\newcommand{\mean}{m}
\newcommand{\likelihood}{{\mathcal L}}
\newcommand{\Poisson}{{\mathcal P}}
\newcommand{\Uniform}{{\mathcal U}}
\newcommand{\bkg}{\mathrm{bkg}}
\newcommand{\word}{\phi}

\DeclareMathOperator\erf{erf}

%\newcommand{\bs}{\boldsymbol}

\begin{document}

\title{Shifty Lines: Probabilistic inference of multiple redshifts from a spectrum}

\author{D. Huppenkothen\altaffilmark{1, 2}, B. J. Brewer\altaffilmark{3}, Victoria Grinberg\altaffilmark{4}}
 
  \altaffiltext{1}{Center for Data Science, New York University, 726 Broadway, 7th Floor, New York, NY 10003}
  \altaffiltext{2}{{\tt daniela.huppenkothen@nyu.edu}}
  \altaffiltext{3}{Department of Statistics, The University of Auckland, Private Bag 92019, Auckland 1142, New Zealand}
  \altaffiltext{4}{MIT Kavli Institute for Astrophysics and Space Research,
MIT, 70 Vassar Street, Cambridge, MA 02139, USA}


\begin{abstract}
Stellar winds and winds from accretion disks have Doppler shifts. Sometimes, there can be more than one Doppler shift in 
the same X-ray spectrum. This project solves the problem where (a) we do not know the line amplitudes and widths, (b) the 
number of Doppler shifts in the system and (c) which line belongs to which Doppler shift.

\end{abstract}

\keywords{methods:statistics}

\section{Introduction}

Accretion disks and winds and stuff.

There are other astrophysical problems where similar questions arise. For
example, many galaxy-galaxy strong gravitational lens systems were
found by the Sloan Lens ACS Survey \citep[SLACS;][]{slacs0, slacs1} by searching
the Sloan Digital Sky Survey for sources whose spectra seemed to contain two
redshifts. Hubble Space Telescope imaging was then used to find the candidates
that were actually gravitational lenses.
The methods used by SLACS to identify two redshifts in a spectrum can be
considered as more heuristic solution to the same problem we consider in this
paper. However, we focus more on the issue of characterizing all of the
uncertainties (i.e. exploring the range of hypotheses plausible given the
spectral data), rather than prioritizing computational speed.

\section{Method}

\subsection{The Spectral Model}
High-resolution spectral data consists of a continuum with a set of spectral lines superposed. A priori, we (approximately) know the rest frame wavelengths of the most common lines, but neither the amplitudes nor widths of these lines is known, thus they should be part of the inference process. Strictly speaking, because rest frame line positions in the spectrum are based on laboratory measurements, they have an uncertainty associated with them, too, but we currently do not take this uncertainty into account in the model.

The objective, given a spectrum and a set of rest frame wavelengths of spectral lines, is to infer the amplitudes and widths of all (potential) lines at the same time as the one or several Doppler shifts affecting the centroid wavelengths of the spectral lines. Not all lines may be present in the data, but we consciously avoid performing model selection tasks for each individual line. Instead, we rephrase the problem as a parameter estimation task only, where the absence of a line will lead to a model preferring a very small amplitude for that line. This reflects our state of knowledge of the system: in practice, it is impossible to distinguish between the absence of a line and a line with a very small amplitude.
At the moment, for any Doppler shift $d_i = v_i/c$, all lines can be present. In principle, the model in its current form may model individual lines as mixtures of lines from several Doppler shifts. Depending on the system of interest, this may or may not have a physical motivation. 

Each line $(i,k), \, k \in \{0, ..., K\}$ for a Doppler shift $d_i \in \{d_0, ..., D\}$ is modelled as a Gaussian with location and scale parameters $\mu_{i,k}$ and $\sigma_{i,k}$ as well as an amplitude $A_{i,k}$, respectively. Note that $A_{i,k}$ is defined as the integrated flux (or counts, depending on the units of the data) over the line. We compute the line flux in each wavelength bin $j$ by integrating the model flux $\mean_j$ within the bin from the lower edge $\lambda_{j, \mathrm{low}}$ to the upper bin edge $\lambda_{j, \mathrm{high}}$:

\begin{eqnarray}
\mean_{\mathrm{lines},j} & = &  \sum_{i=1}^{D}\sum_{k=1}^{K}{\int^{\lambda_{j,\mathrm{high}}}_{\lambda_{j, \mathrm{low}}}{\frac{A_{k}}{\sigma_{k}\sqrt{2\pi}} \exp{(-(\lambda-\mu_{k})/{2\sigma_{k}^2})}}} \\ \nonumber
& = & \frac{1}{2}  \sum_{i=1}^{D} \sum_{k=1}^{K} A_{i,k}\left[ \erf{\left( \frac{\lambda_{j,\mathrm{high}} - \mu_{k}}{\sigma_{k}\sqrt{2}}\right)} - \erf{\left( \frac{\lambda_{j, \mathrm{low}} - \mu_{k}}{\sigma_{i,k}\sqrt{2}}\right)} \right] \; ,
\end{eqnarray}

\noindent where $j$ is the index of a wavelength bin and $\erf$ defines the error function. 

X-ray spectra have very noticeable continuum contributions as well as calibration that needs to be performed on the data. In most high-resolution spectra, the continuum will be fit separately to the data and then divided out before attempting line fits. In principle, the statistically consistent approach to the model we propose here would be to fit continuum parameters at the same time as the spectral lines. Because both continuum modelling and calibration is a non-trivial task for high-resolution spectroscopy, we do not attempt in this work to include this contribution, but note that there is scope for improvement in this direction in the future. 
Instead, we choose a simple model to account for residual continuum contributions and potential biases due to incorrect calibration by modeling the continuum by a combination of a simple constant model $\mean_{\mathrm{bkg}}$ and an autoregressive process called an Ornstein-Uhlenbeck (OU) process. The latter is a damped random walk capable of modelling trends in the data as well as smaller irregularities. It adds two parameters to the model: a length scale $\tau_{\mathrm{OU}}$ describing the interval within which correlations are important, and an amplitude $A_{\mathrm{OU}}$ describing the variance of the induced fluctuations. 
We regard these parameters as nuisance parameters, which will be sampled along with the remaining parameters of the model and integrated out for the final parameter estimates. 
Thus, the complete model for an observed X-ray spectrum is

\begin{equation}
\label{eqn:modelflux}
m_j = m_{\mathrm{lines},j} + m_{\mathrm{bkg}}*\mathrm{OU}(\lambda_j, \tau_{\mathrm{OU}}, A_{\mathrm{OU}} \; .
\end{equation}

\noindent This assumes that the spectral lines are independent of any continuum and calibration errors that were not removed in the pre-processing. 

\subsection{The hierarchical model}

We now build a hierarchical model to infer the number of different Doppler shifts present in the data, the values of $d_i$ themselves as well as the line properties ${\pars_{i,k}}$ for each line $k$ and each Doppler shift $d_i$. In order to keep the model fairly simple, we assume that the line amplitudes and widths for different Doppler shifts share the same priors. This may not be a reasonable assumption for all spectral modelling problems, and we note that in future versions, this may be changed, though at the moment we prefer simplicity over complexity. 

In addition, we also infer a number of hyperparameters $\alpha$ describing the prior distributions for the line widths and amplitudes (see Section \ref{sec:priors} for details) as well as the constant background and the parameters of the OU process: $\beta = \{\mean_{\bkg}, \tau_{\mathrm{OU}}, A_{\mathrm{OU}}\}$.

The posterior distribution over all the parameters takes the form

\begin{eqnarray}
p(D, \{d_i\}, \alpha, \beta, \{\bm{\pars_{i,k}}\} \given  \bm{\counts}, H) & = & \likelihood(D, \{d_i\}, \bm{\alpha}, \beta, \{\bm{\pars_{i,k}}\}) \\\nonumber
					& & \times \pi(D, \{d_i\}, \alpha, \beta, \{\bm{\pars_{i,k}}\} \given H) \\\nonumber
					& &  / p(\bm{\counts} \given H)\; ,
\end{eqnarray} 

\noindent where $\likelihood(D, \{d_i\}, \bm{\alpha}, \beta, \{\bm{\pars_{i,k}}\})$ describes the likelihood of the data and $\pi(D, \{d_i\}, \alpha, \beta, \{\bm{\pars_{i,k}}\} $ the prior. $H$ stands in as a place-holder for all other assumptions made in the model, including the shape of the priors and the sampling distribution chosen in the likelihood. The distribution $p(\bm{\counts} \given H)$ is called the marginal likelihood or Bayesian evidence and in effect a normalization that ensures the posterior to be a proper probability distribution:

\begin{eqnarray}
p(\bm{\counts} \given H) & = & \int_\Omega{ \likelihood(D, \{d_i\}, \bm{\alpha}, \beta, \{\bm{\pars_{i,k}}\}) } \\\nonumber
					& &{ \times \pi(D, \{d_i\}, \alpha, \beta, \{\bm{\pars_{i,k}}\} \given H) d\Omega} \; ,
\end{eqnarray}

\noindent where $\Omega$ describes the volume of the entire parameter space allowed by the prior. The marginal likelihood is of use in particular in a model comparison context, where it is used to compute the posterior of a model $H$ given the data $\bm{\counts}$: $p(H \given \bm{\counts}) \propto p(D \given H) p(H)$. In practice, however, it is a high-dimensional integral with generally no analytic solution and thus often very difficult to compute.

The likelihood is defined as the probability of observing the data $\bm{\counts}$ given a specific set of hyperparameters $\alpha$, and parameters $\beta$, $D$ and $\{\pars_{i,k}$. Because we work mostly with high signal-to-noise data in flux space, and much of it has been pre-processed, we choose a Gaussian sampling distribution, such that the likelihood becomes:

\begin{eqnarray}
\likelihood(D, \bm{\alpha}, \{\bm{\pars_{i,k}}\}) & = & p(\bm{\counts} \given D, \{d_i\}, \alpha, \beta, \{\bm{\pars_{i,k}}\}, H) \\ \nonumber
			& = & \prod_{j=1}^{J}{p(\counts_j \given D, \{d_i\}, \alpha, \beta, \{\bm{\pars_{i,k}}\}, H)} \\\nonumber
			& = & \prod_{j=1}^{J}{\frac{1}{\sigma_j \sqrt{2\pi}}\exp{\left(\frac{(\counts_j - \mean_j)^2}{2\sigma_j^2} \right)}} \; ,
\end{eqnarray}	
\noindent where $\sigma_j$ describes the uncertainty on the $j$th data point and $\mean_j$ describes the model flux as defined in Equation \ref{eqn:modelflux}. In reality, we compute the logarithm of the likelihood, which simply reduces to

\begin{eqnarray}
\log{\likelihood(D, \{d_i\}, \bm{\alpha}, \{\bm{\pars_{i,k}}\})} = & \sum_{j=1}^{J} & \left[ -\log{\sigma_j} - \log{\sqrt{2\pi}} \right. \\ \nonumber
					 & & \left. -\frac{1}{\sigma_j \sqrt{2\pi}}\left(\frac{(\counts_j - \mean_j)^2}{2\sigma_j^2} \right)\right] \; .
\end{eqnarray}

For the prior distributions, we assume independence between the individual parameters as well as hyperparameters, such that the 
prior  $\pi(D, \{d_i\}, \alpha, \beta, \{\bm{\pars_{i,k}}\} $ can be split up into simpler distributions:

\begin{eqnarray}
\pi(D, \{d_i\}, \alpha, \beta, \{\bm{\pars_{i,k}}\} ) & = &  p(D \given H) p(\alpha \given H) p(\beta \given H)   \nonumber \\	
					& & \times \prod_{i=1}^{D}{\left[p(d_i \given H) \prod_{k=1}^{K}{p( \{\bm{\pars_{i,k}}\} \given \alpha, H)}\right]} 
\end{eqnarray}


\subsection{Priors}
\label{sec:priors}

Here we list all the priors in the model.


\begin{table*}[hbtp]
\renewcommand{\arraystretch}{1.3}
\footnotesize
\caption{Model Parameters and Prior Probability Distributions}
%\resizebox{\textwidth}{!}{%
\begin{threeparttable} 
\begin{tabularx}{\textwidth}{p{4.0cm}p{7.0cm}X}%lrrrllll}%{lrrrllll}
%\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}} cll}%lrrrllll}%{lrrrllll}
%\begin{tabular}{|l|r|r|l|r|r|r|r|l|}
\toprule
\bf{Parameter} & \bf{Meaning} & \bf{Probability Distribution} \\ \midrule
\it{Hyperparameters} && \\ \midrule
$\mu_{\log{A}}$ & Mean of Laplacian prior distribution for line amplitude $\log{A}$ &   $\mathrm{truncated\, Cauchy\, distribution}(10^{-21}, 10^{21})$  \\
$\sigma_{\log{A}}$ & Standard deviation of Laplacian prior distribution for line amplitude $\log{A}$ & $\mathrm{Uniform}(0,2)$ \\
$\mu_{\log{w}}$ & Mean of Laplacian prior distribution for the log-width $\log{w}$ & $\mathrm{Uniform}(\log{\min{\Delta\lambda}/5}, \log{0.1})$  \\
$\sigma_{\log{w}}$ & Standard deviation of the Laplacian prior distribution for the log-width $\log{w}$ & $\mathrm{Uniform}(\log{0}, \log{0.3})$\\ 
$\alpha$ & Threshold parameter for the amplitude signs (determining emission/absorption lines) &  $\mathrm{Uniform}(0,1)$\\
\midrule
\it{Individual Spectral Line Parameters} && \\ \midrule
$\log{A_k}$ & logarithm of the amplitude of line $k$ & $\mathrm{Laplacian}(\mu_A \sigma_A)$ \\
$\log{w_k}$ & logarithm of the line width & $\mathrm{Laplacian}(\mu_{\log{w}}, \sigma_{\log{w}})$ \\
$\log{\counts}_{\mathrm{bkg}}$ & logarithm of the background flux & $\mathrm{truncated\, Cauchy\, distribution}(10^{-21}, 10^{21})$ \\
$s_k$ & sign of each spectral line (determining either emission or absorption line) &  $\mathrm{Uniform}(0,1)$\\
\midrule
\it{Other Model Parameters} && \\ \midrule
$d = v/c$ & Doppler shift $d$ parametrized as a function of velocity $v$ and speed of light $c$ & $\mathrm{Uniform}(-0.1, 0.1)$ \\
$N$ & Number of possible Doppler shifts & $\mathrm{Uniform}(0,5)$  \\
$\log{A_{\mathrm{OU}}}$ & Amplitude of the OU process & \\
$\log{\tau_{\mathrm{OU}}}$ & length scale of the OU process & \\
\bottomrule
\end{tabularx}
   \begin{tablenotes}
      %\footnotesize
      \item{An overview over the model parameters and hyperparameters with their respective prior probability distributions.}
     %\item[\emph{a}]{See Section \ref{ch6:priortest} for a discussion on testing an alternative, log-normal prior for spike amplitude and exponential rise time scale.}
     %\item[\emph{a}]{$T_\mathrm{b}$: duration of total burst}
\end{tablenotes}
\end{threeparttable}
\label{tab:priortable}
%\tablecomments{An overview over the model parameters and hyperparameters with their respective prior probability distributions. For parameters where we have explored an alternative distribution in Section 
%\ref{ch6:priortest}, we give parameters and distributions for both priors.}
%\end{sidewaystable}
\end{table*}



\section{Simulated Data}

\subsection{Discussion on where assumptions fail}

Need to talk here about how the likelihood is multi-modal and sometimes the modes can be very narrow. 
This is a problem that makes all sampling algorithms fail, and requires careful tuning.


\section{Observations}

\section{Results}


\section{Discussions}



\paragraph{Acknowledgements}
DH was supported by the Moore-Sloan Data Science Environment at NYU.
BJB was supported by a Marsden Fast-Start grant from the Royal Society of
New Zealand.

\bibliography{td}
\bibliographystyle{apj}
\begin{thebibliography}{999}

\bibitem[Bolton et al.(2005)]{slacs0} Bolton, A.~S., Burles, 
S., Koopmans, L.~V.~E., Treu, T., 
\& Moustakas, L.~A.\ 2005, \apjl, 624, L21 

\bibitem[Bolton et al.(2006)]{slacs1} Bolton, A.~S., Burles, 
S., Koopmans, L.~V.~E., Treu, T., \& Moustakas, L.~A.\ 2006, \apj, 638, 703 

\end{thebibliography}

\end{document}


