{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifty Lines: Line Detection and Doppler Shift Estimation\n",
    "\n",
    "We have some X-ray spectra that have absorption and emission lines in it. The original spectrum is seen through a stellar wind, which moves either toward or away from us, Doppler-shifting the absorbed lines. Not all lines will be absorbed, some may be at their original position. There may also be more than one redshift in the same spectrum.\n",
    "There are various other complications: for example, we rarely have the complete spectrum, but separate intervals of it (due to issues with calibration). In principle, however, the other segments may give valuable information about any other given segment.\n",
    "\n",
    "\n",
    "Simplest problem: estimating Doppler shift and line presence at the same time\n",
    "\n",
    "Second-simplest problem: some lines are Doppler shifted, some are not\n",
    "\n",
    "Full problem: estimating the number of redshifts and the lines belonging to each in the same model\n",
    "\n",
    "Note: we are going to need to add some kind of OU process or spline to model the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=2.5, rc={\"axes.labelsize\": 26})\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "plt.rc(\"font\", size=24, family=\"serif\", serif=\"Computer Sans\")\n",
    "plt.rc(\"text\", usetex=True)\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import shutil\n",
    "\n",
    "from astropy import units\n",
    "import astropy.constants as const\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import dnest4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load our first example spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = \"../data/\"\n",
    "datafile = \"8525_nodip_0.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(datadir+datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavelength_left = data[:,0]\n",
    "wavelength_right = data[:,1]\n",
    "\n",
    "wavelength_mid = data[:,0] + (data[:,1]-data[:,0])/2.\n",
    "counts = data[:,2]\n",
    "counts_err = data[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(wavelength_mid, counts)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlim(wavelength_mid[-1], wavelength_mid[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to need the lines we're interested in. Let's use the Silicon lines. Note that these are all in *electron volt*. However, the data are in *Angstrom*, which means I need to convert them. \n",
    "\n",
    "I'm going to use `astropy.units` to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siXIV = 1864.9995 * units.eV\n",
    "siXIII = 2005.494 * units.eV\n",
    "\n",
    "siXII = 1845.02 * units.eV\n",
    "siXII_err = 0.07 * units.eV\n",
    "\n",
    "siXI = 1827.51 * units.eV\n",
    "siXI_err = 0.06 * units.eV\n",
    "\n",
    "siX = 1808.39 * units.eV\n",
    "siX_err = 0.05 * units.eV\n",
    "\n",
    "siIX = 1789.57 * units.eV\n",
    "siIX_err = 0.07 * units.eV\n",
    "\n",
    "siVIII = 1772.01 * units.eV\n",
    "siVIII_err = 0.09 * units.eV\n",
    "\n",
    "siVII = 1756.68 * units.eV\n",
    "siVII_err = 0.08 * units.eV\n",
    "\n",
    "si_all = [siXIV, siXIII, siXII, siXI, siX, siIX, siVIII, siVII]\n",
    "si_err_all = [0.0*units.eV, 0.0*units.eV, siXII_err, siXI_err, \n",
    "              siX_err, siIX_err, siVIII_err, siVII_err]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can do the actual conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "si_all_angstrom = [(const.h*const.c/s.to(units.Joule)).to(units.Angstrom) \n",
    "                   for s in si_all]\n",
    "si_err_all_angstrom = [(const.h*const.c/s.to(units.Joule)).to(units.Angstrom) \n",
    "                       for s in si_err_all]\n",
    "\n",
    "si_err_all_angstrom[0] = 0.0*units.Angstrom\n",
    "si_err_all_angstrom[1] = 0.0*units.Angstrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in si_all_angstrom:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the lines onto the spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.errorbar(wavelength_mid, counts, yerr=counts_err, fmt=\"o\")\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlim(wavelength_mid[-1], wavelength_mid[0])\n",
    "for s in si_all_angstrom:\n",
    "    plt.vlines(s.value, np.min(counts), np.max(counts), lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently don't have the positions of the longer-wavelength lines, so we're going to cut the spectrum at 7.1 Angstrom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxind = wavelength_mid.searchsorted(7.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wnew_mid = wavelength_mid[:maxind]\n",
    "wnew_left = wavelength_left[:maxind]\n",
    "wnew_right = wavelength_right[:maxind]\n",
    "\n",
    "cnew = counts[:maxind]\n",
    "enew = counts_err[:maxind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.errorbar(wnew_mid, cnew, yerr=enew, fmt=\"o\")\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlim(wnew_mid[-1], wnew_mid[0])\n",
    "for s in si_all_angstrom:\n",
    "    plt.vlines(s.value, np.min(counts), np.max(counts), lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to save the spectrum as well as the line centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the full spectrum in a format usable by ShiftyLines\n",
    "np.savetxt(datadir+\"8525_nodip_full.txt\", np.array([wavelength_left, wavelength_right,\n",
    "                                                   counts, counts_err]).T)\n",
    "\n",
    "# the cut spectrum with the Si lines only\n",
    "np.savetxt(datadir+\"8525_nodip_cut.txt\", np.array([wnew_left, wnew_right, cnew, enew]).T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert from astropy.units to float\n",
    "si_all_val = np.array([s.value for s in si_all_angstrom])\n",
    "si_err_all_val = np.array([s.value for s in si_err_all_angstrom])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(datadir+\"si_lines.txt\", np.array(si_all_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding some more lines for later\n",
    "\n",
    "We have some more lines that are going to become important/interesting later, because \n",
    "they'll be shifted at a different redshift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# line energies in keV\n",
    "al_ly_alpha = 1.72855 * 1000 * units.eV\n",
    "mg_he_gamma = 1.65910 * 1000 * units.eV\n",
    "mg_he_delta = 1.69606 * 1000 * units.eV\n",
    "mg_ly_beta = 1.74474 * 1000 * units.eV\n",
    "mg_ly_gamma = 1.84010 * 1000 * units.eV\n",
    "mg_ly_delta = 1.88423 * 1000 * units.eV\n",
    "fe_xxiv = 1.88494 * 1000 * units.eV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines need to be converted to Angstroms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "other_lines_all = [al_ly_alpha, mg_he_gamma, mg_ly_beta, mg_ly_gamma, mg_ly_delta, fe_xxiv]\n",
    "\n",
    "other_lines_all_angstrom = [(const.h*const.c/s.to(units.Joule)).to(units.Angstrom) \n",
    "                   for s in other_lines_all]\n",
    "\n",
    "other_lines_all_val = np.array([s.value for s in other_lines_all_angstrom])\n",
    "\n",
    "for l in other_lines_all_angstrom:\n",
    "    print(str(l.value) + \" \" +  str(l.unit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the spectrum with the line centroids look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.errorbar(wavelength_mid, counts, yerr=counts_err, fmt=\"o\")\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlim(wavelength_mid[-1], wavelength_mid[0])\n",
    "for s in si_all_angstrom:\n",
    "    plt.vlines(s.value, np.min(counts), np.max(counts), lw=2)\n",
    "for l in other_lines_all_angstrom:\n",
    "    plt.vlines(l.value, np.min(counts), np.max(counts), lw=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the extended list of lines to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make extended array of lines\n",
    "lines_extended = np.hstack([si_all_val, other_lines_all_val])\n",
    "\n",
    "# save the lines\n",
    "np.savetxt(datadir+\"lines_extended.txt\", np.array(lines_extended))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Data\n",
    "\n",
    "In order to test any methods we are creating, we are first going to produce some simulated data. \n",
    "\n",
    "Set the seed so that the output simulations will always be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(20160216)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectral lines are modelled as simple Gaussians with an amplitude $A$, a width $\\sigma$ and a position $\\lambda_0$. \n",
    "\n",
    "Because energy data comes naturally binned (the original channels detect photons between a certain minimum and maximum energy), we *integrate* over energy bins to get an accurate estimate of the flux in each energy bin. This also allows the use of uneven binning.\n",
    "\n",
    "In order to integrate over the bins correctly, I also define the cumulative distribution function (CDF) of a Gaussian below, which is, in fact, the integral of the Gaussian function.\n",
    "\n",
    "This also means that the amplitude is defined as the integrated area under the Gaussian rather than the height of the Gaussian, but this is closer to the physical quantities astronomers might be interested in (equivalent width) anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def gaussian_cdf(x, w0, width):\n",
    "    return 0.5*(1. + scipy.special.erf((x-w0)/(width*np.sqrt(2.))))\n",
    "\n",
    "def spectral_line(wleft, wright, w0, amplitude, width):\n",
    "    \"\"\"\n",
    "    Use the CDF of a Gaussian distribution to define spectral \n",
    "    lines. We use the CDF to integrate over the energy bins, \n",
    "    rather than taking the mid-bin energy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wleft: array\n",
    "        Left edges of the energy bins\n",
    "        \n",
    "    wright: array\n",
    "        Right edges of the energy bins\n",
    "        \n",
    "    w0: float\n",
    "        The centroid of the line\n",
    "        \n",
    "    amplitude: float\n",
    "        The amplitude of the line\n",
    "        \n",
    "    width: float\n",
    "        The width of the line\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    line_flux: array\n",
    "        The array of line fluxes integrated over each bin\n",
    "    \"\"\"\n",
    "    line_flux = amplitude*(gaussian_cdf(wright, w0, width)-\n",
    "                           gaussian_cdf(wleft, w0, width))\n",
    "    return line_flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w0 = 6.6\n",
    "amp = 0.01\n",
    "width = 0.01\n",
    "\n",
    "line_flux = spectral_line(wnew_left, wnew_right, w0, amp, width)\n",
    "\n",
    "plt.plot(wnew_mid, line_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Spectra\n",
    "\n",
    "In order to test our algorithm, we'd like to simulate some test data where we know the \"ground truth\" (i.e. the input parameters that made the spectrum).\n",
    "\n",
    "Below is a (admittedly complicated) function that will simulate data for various test cases.\n",
    "We'll address these test cases one by one below and simulate a spectrum to test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fake_spectrum(wleft, wright, line_pos, logbkg=np.log(0.09), err=0.007, dshift=0.0,\n",
    "                  sample_logamp=False, sample_logq=False, sample_signs=False,\n",
    "                  logamp_hypermean=None, logamp_hypersigma=np.log(0.08), nzero=0, \n",
    "                  logq_hypermean=np.log(500), logq_hypersigma=np.log(50)):\n",
    "    \"\"\"\n",
    "    Make a fake spectrum with emission/absorption lines.\n",
    "    The background is constant, though that should later become an OU process or \n",
    "    something similar.\n",
    "    \n",
    "    NOTE: The amplitude *must not* fall below zero! I'm not entirely sure how to deal \n",
    "    with that yet!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wleft: np.ndarray\n",
    "        Left edges of the energy bins\n",
    "        \n",
    "    wright: np.ndarray\n",
    "        Right edges of the energy bins\n",
    "    \n",
    "    line_pos: np.ndarray\n",
    "        The positions of the line centroids\n",
    "    \n",
    "    bkg: float\n",
    "        The value of the constant background\n",
    "        \n",
    "    err: float\n",
    "        The width of the Gaussian error distribution\n",
    "        \n",
    "    dshift: float, default 0.0\n",
    "        The Doppler shift of the spectral lines.\n",
    "        \n",
    "    sample_amp: bool, default False\n",
    "        Sample all amplitudes? If not, whatever value is set in \n",
    "        `amp_hypermean` will be set as collective amplitude for all \n",
    "        lines\n",
    "        \n",
    "    sample_width: bool, default False\n",
    "        Sample all line widths?  If not, whatever value is set in \n",
    "        `width_hypersigma` will be set as collective amplitude for all \n",
    "        lines\n",
    "    \n",
    "    sample_signs: bool, default False\n",
    "        Sample the sign of the line amplitude (i.e. whether the line is an \n",
    "        absorption or emission line)? If False, all lines will be absorption \n",
    "        lines\n",
    "        \n",
    "    logamp_hypermean: {float | None}, default None\n",
    "        The mean of the Gaussian prior distribution on the line amplitude. If None, \n",
    "        it is set to the same value as `bkg`.\n",
    "        \n",
    "    logamp_hypersigma: float, default 0.08\n",
    "        The width of the Gaussian prior distribution on the line amplitude. \n",
    "        \n",
    "    nzero: int, default 0\n",
    "        The number of lines to set to zero amplitude\n",
    "        \n",
    "    logq_hypermean: float, default 0.01\n",
    "        The mean of the Gaussian prior distribution on the \n",
    "        q-factor, q=(line centroid wavelength)/(line width)\n",
    "        \n",
    "    logq_hypersigma: float, default 0.01\n",
    "        The width of the Gaussian prior distribution on the\n",
    "        q-factor, q=(line centroid wavelength)/(line width)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model_flux: np.ndarray\n",
    "        The array of model line fluxes for each bin\n",
    "        \n",
    "    fake_flux: np.ndarray\n",
    "        The array of fake fluxes (with errors) for each bin\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # number of lines\n",
    "    nlines = line_pos.shape[0]\n",
    "    \n",
    "    # shift spectral lines\n",
    "    line_pos_shifted = line_pos*(1. + dshift)\n",
    "   \n",
    "    # if sampling the amplitudes\n",
    "    if sample_logamp:  \n",
    "        # sample line amplitudes\n",
    "        logamps = np.random.normal(logamp_hypermean, logamp_hypersigma, size=nlines)\n",
    "    else:\n",
    "        logamps = np.zeros(nlines)+logamp_hypermean\n",
    "        \n",
    "    \n",
    "    amps = np.exp(logamps)\n",
    "    \n",
    "    if nzero > 0:\n",
    "        zero_ind = np.random.choice(np.arange(nlines), size=nzero)\n",
    "        for z in zero_ind:\n",
    "            amps[int(z)] = 0.0\n",
    "    \n",
    "    if sample_signs:\n",
    "        # sample sign of the amplitudes\n",
    "        signs = np.random.choice([-1., 1.], p=[0.5, 0.5], size=nlines)\n",
    "    else:\n",
    "        # all lines are absorption lines\n",
    "        signs = -1.*np.ones(nlines)\n",
    "        \n",
    "    # include signs in the amplitudes\n",
    "    amps *= signs\n",
    "    \n",
    "    if sample_logq:\n",
    "        # widths of the lines\n",
    "        logq = np.random.normal(logq_hypermean, logq_hypersigma, size=nlines)\n",
    "    else:\n",
    "        logq = np.ones(nlines)*logq_hypermean\n",
    "        \n",
    "        \n",
    "    widths = line_pos_shifted/np.exp(logq)\n",
    "    \n",
    "    model_flux = np.zeros_like(wleft) + np.exp(logbkg)\n",
    "    \n",
    "    for si, a, w in zip(line_pos_shifted, amps, widths):\n",
    "        model_flux += spectral_line(wleft, wright, si, a, w)\n",
    "      \n",
    "    fake_flux = model_flux + np.random.normal(0.0, 0.007, size=model_flux.shape[0])\n",
    "    \n",
    "    pars = {\"wavelength_left\": wleft, \"wavelength_right\": wright, \"err\":err,\n",
    "            \"model_flux\": model_flux, \"fake_flux\": fake_flux, \"logbkg\":logbkg,\n",
    "            \"dshift\": dshift, \"line_pos\": line_pos_shifted, \"logamp\": logamps,\n",
    "           \"signs\": signs, \"logq\": logq }\n",
    "    \n",
    "    \n",
    "    return pars\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: A spectrum with no redshift and strong lines\n",
    "\n",
    "As a first simple check, we simulate a spectrum with strong absorption lines at all available line positions. The amplitudes and widths ($q$-values) are the same for all lines. There is no Doppler shift.\n",
    "\n",
    "We use the wavelength bins from the real data for generating the simulation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "froot = \"test_noshift1\"\n",
    "\n",
    "## set amplitude and q\n",
    "logamp_mean = np.log(0.3)\n",
    "logq_mean = np.log(600.)\n",
    "\n",
    "# set Doppler shift\n",
    "dshift = 0.0\n",
    "\n",
    "# set background\n",
    "logbkg = np.log(0.09)\n",
    "\n",
    "# do not sample amplitudes or q-factors(all are the same!)\n",
    "sample_logamp = False\n",
    "sample_logq = False\n",
    "\n",
    "# all lines are absorption lines\n",
    "sample_signs = False\n",
    "\n",
    "# error on the data points (will sample from a Gaussian distribution)\n",
    "err = 0.007\n",
    "\n",
    "# do not set any lines to zero!\n",
    "nzero = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pars = fake_spectrum(wnew_left, wnew_right, si_all_val, logbkg=logbkg, err=err, \n",
    "                     dshift=dshift, sample_logamp=sample_logamp, sample_logq=sample_logq, \n",
    "                     logamp_hypermean=logamp_mean, logq_hypermean=logq_mean, \n",
    "                     sample_signs=sample_signs, nzero=nzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_flux = pars[\"model_flux\"]\n",
    "fake_flux = pars[\"fake_flux\"]\n",
    "\n",
    "fake_err = np.zeros_like(fake_flux) + pars[\"err\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.errorbar(wnew_mid, fake_flux, yerr=fake_err, fmt=\"o\", label=\"simulated flux\", alpha=0.7)\n",
    "plt.plot(wnew_mid, model_flux, label=\"simulated model\", lw=3)\n",
    "plt.xlim(wnew_mid[0], wnew_mid[-1])\n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend(prop={\"size\":18})\n",
    "plt.xlabel(\"Wavelength [Angstrom]\")\n",
    "plt.ylabel(\"Normalized Flux\")\n",
    "plt.savefig(datadir+froot+\"_lc.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We're going to save the data and the parameters in a pickle file for later use. We'll also save the fake data itself in a way that I can easily input it into `ShiftyLines`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the whole dictionary in a pickle file\n",
    "f = open(datadir+froot+\"_data.pkl\", \"w\")\n",
    "pickle.dump(pars, f)\n",
    "f.close()\n",
    "\n",
    "# save the fake data in an ASCII file for input into ShiftyLines\n",
    "np.savetxt(datadir+froot+\".txt\", np.array([wnew_left, wnew_right, fake_flux, fake_err]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the Model\n",
    "\n",
    "If `DNest4` and `ShiftyLines` are installed and compiled, you should now be able to run this model (from the `ShiftyLines/code/` directory) with\n",
    "    \n",
    "    >>> ./main -d ../data/test_noshift1.txt -t 8\n",
    "\n",
    "The last option sets the number of threads to run; this will depend on your computer and how many CPUs you can keep busy with this.\n",
    "\n",
    "In this run, we set the number of levels in the `OPTIONS` file to $100$, based on running the sampler until the likelihood change between two levels fell below $1$ or so.\n",
    "\n",
    "### Results\n",
    "\n",
    "Here are the results of the initial simulation. For this run, we set the number of Doppler shifts to exactly $1$ and do not sample over redshifts. This means the model is equivalent to simple template fitting, but it makes a fairly good test.\n",
    "\n",
    "First, we need to move the posterior run to a new directory so it doesn't get overwritten by subsequent runs. We'll write a function for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "def move_dnest_output(froot, dnest_dir=\"./\"):\n",
    "    shutil.move(dnest_dir+\"posterior_sample.txt\", froot+\"_posterior_sample.txt\")\n",
    "    shutil.move(dnest_dir+\"sample.txt\", froot+\"_sample.txt\")\n",
    "    shutil.move(dnest_dir+\"sample_info.txt\", froot+\"_sample_info.txt\")\n",
    "    shutil.move(dnest_dir+\"weights.txt\", froot+\"_weights.txt\")\n",
    "    shutil.move(dnest_dir+\"levels.txt\", froot+\"_levels.txt\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move_dnest_output(\"../data/%s\"%froot, \"../code/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to load the data and the posterior samples for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the pickle file with the data + parameters:\n",
    "f = open(datadir+froot+\"_data.pkl\")\n",
    "data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "print(\"Keys in data dictionary: \" + str(data.keys()))\n",
    "\n",
    "# the posterior samples\n",
    "sample = np.atleast_2d(np.loadtxt(datadir+froot+\"_posterior_sample.txt\"))\n",
    "nsamples = sample.shape[0]\n",
    "print(\"We have %i samples from the posterior.\"%nsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First plot: a random set of realizations from the posterior overplotted on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly pick some samples from the posterior to plot\n",
    "s_ind = np.random.choice(np.arange(nsamples, dtype=int), size=20)\n",
    "\n",
    "# the middle of the wavelength bins for plotting\n",
    "wmid = data[\"wavelength_left\"] + (data[\"wavelength_right\"] - data[\"wavelength_left\"])/2.\n",
    "\n",
    "# the error on the data\n",
    "yerr = np.zeros_like(wmid) + data['err']\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.errorbar(wmid, data[\"fake_flux\"], yerr=yerr, fmt=\"o\")\n",
    "for i in s_ind:\n",
    "    plt.plot(wmid, sample[i,-wmid.shape[0]:], lw=2, alpha=0.7)\n",
    "\n",
    "plt.xlim(wmid[0], wmid[-1])\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel(\"Wavelength [Angstrom]\")\n",
    "plt.ylabel(\"Normalized Flux\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(datadir+froot+\"_samples.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the posterior distribution over the constant background?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,9))\n",
    "# Plot a historgram and kernel density estimate\n",
    "ax = fig.add_subplot(111)\n",
    "sns.distplot(sample[:,0], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "_, ymax = ax.get_ylim()\n",
    "\n",
    "ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "ax.set_xlabel(\"Normalized Background Flux\")\n",
    "ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(datadir+froot+\"_bkg.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the OU process modelling the variable background look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,6))\n",
    "sns.distplot(sample[:,1], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax1)\n",
    "#_, ymax = ax.get_ylim()\n",
    "#ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "ax1.set_xlabel(r\"OU time scale $\\tau$\")\n",
    "ax1.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "\n",
    "sns.distplot(sample[:,2], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax2)\n",
    "#_, ymax = ax.get_ylim()\n",
    "#ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "ax2.set_xlabel(r\"OU amplitude\")\n",
    "ax2.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(datadir+froot+\"_ou.png\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the hyperparameters for the log-amplitude and log-q priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,6))\n",
    "sns.distplot(np.log(sample[:,5]), hist_kws={\"histtype\":\"stepfilled\"}, ax=ax1)\n",
    "_, ymax = ax1.get_ylim()\n",
    "ax1.vlines(data[\"logamp\"], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "ax1.set_xlabel(r\"$\\mu_{\\mathrm{\\log{A}}}$\")\n",
    "ax1.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "ax1.set_title(\"Location parameter of the amplitude prior\")\n",
    "\n",
    "\n",
    "sns.distplot(sample[:,6], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax2)\n",
    "#_, ymax = ax.get_ylim()\n",
    "#ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "ax2.set_xlabel(r\"$\\sigma_{\\mathrm{\\log{A}}}$\")\n",
    "ax2.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "ax2.set_title(\"Scale parameter of the amplitude prior\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(datadir+froot+\"_logamp_prior.png\", format=\"png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the width:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,6))\n",
    "sns.distplot(sample[:,7], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax1)\n",
    "_, ymax = ax1.get_ylim()\n",
    "ax1.vlines(data[\"logq\"], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "ax1.set_xlabel(r\"$\\mu_{\\mathrm{\\log{q}}}$\")\n",
    "ax1.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "ax1.set_title(r\"Location parameter of the $q$ prior\")\n",
    "\n",
    "\n",
    "sns.distplot(sample[:,8], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax2)\n",
    "#_, ymax = ax.get_ylim()\n",
    "#ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "ax2.set_xlabel(r\"$\\sigma_{\\mathrm{\\log{q}}}$\")\n",
    "ax2.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "ax2.set_title(r\"Scale parameter of the $q$ prior\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(datadir+froot+\"_logq_prior.png\", format=\"png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next parameter (`pp`) in the model is the threshold determining the sign of the amplitude (i.e. whether a line is an absorption or an emission line). The sign is sampled as a random variable between $0$ and $1$; the threshold sets the boundary below which a line will become an absorption line. Above the threshold, the sign will be flipped to return an emission line.\n",
    "\n",
    "For a spectrum with mostly absorption lines, `pp` should be quite high, close to $1$. For a spectrum with mostly emission lines, `pp` should be close to $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,9))\n",
    "# Plot a historgram and kernel density estimate\n",
    "ax = fig.add_subplot(111)\n",
    "sns.distplot(sample[:,9], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Threshold parameter\")\n",
    "ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(datadir+froot+\"_pp.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, the model doesn't seem to care much about that? Funny!\n",
    "\n",
    "The Doppler shift is next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,9))\n",
    "plt.locator_params(axis = 'x', nbins = 6)\n",
    "\n",
    "# Plot a historgram and kernel density estimate\n",
    "ax = fig.add_subplot(111)\n",
    "sns.distplot(sample[:,11], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "_, ymax = ax.get_ylim()\n",
    "ax.vlines(data[\"dshift\"], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "ax.set_xlabel(r\"Doppler shift $d=v/c$\")\n",
    "ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(datadir+froot+\"_dshift.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the posterior on all the line amplitudes and widths? Let's try overplotting them all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlines = 8\n",
    "ncolumns = 3\n",
    "nrows = int(nlines/3)+1\n",
    "\n",
    "fig = plt.figure(figsize=(nrows*4,ncolumns*4))\n",
    "plt.locator_params(axis = 'x', nbins = 6)\n",
    "\n",
    "# log-amplitudes\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(nrows, ncolumns, i+1)    \n",
    "    sns.distplot(sample[:,12+i], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "    #ax.hist(sample[:,12+i], histtype=\"stepfilled\", alpha=0.7)\n",
    "    plt.locator_params(axis = 'x', nbins = 6)\n",
    "    xlabels = ax.get_xticklabels() \n",
    "    for l in xlabels: \n",
    "        l.set_rotation(45) \n",
    "\n",
    "    _, ymax = ax.get_ylim()\n",
    "    ax.vlines(data[\"logamp\"][i], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax.set_xlabel(r\"$\\log{A}$\")\n",
    "    ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(datadir+froot+\"_logamp.png\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it samples amplitudes correctly! Let's make the same Figure for log-q:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(ncolumns*4,nrows*4))\n",
    "plt.locator_params(axis = 'x', nbins = 6)\n",
    "\n",
    "# log-amplitudes\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(nrows, ncolumns, i+1)    \n",
    "    sns.distplot(sample[:,20+i], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "    #ax.hist(sample[:,20+i], histtype=\"stepfilled\", alpha=0.7)\n",
    "    plt.locator_params(axis = 'x', nbins = 6)\n",
    "    xlabels = ax.get_xticklabels() \n",
    "    for l in xlabels: \n",
    "        l.set_rotation(45) \n",
    "\n",
    "    _, ymax = ax.get_ylim()\n",
    "    ax.vlines(data[\"logq\"][i], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax.set_xlabel(r\"$\\log{q}$\")\n",
    "    ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(datadir+froot+\"_logq.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final thing, just to be sure: the signs of the amplitudes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,9))\n",
    "plt.locator_params(axis = 'x', nbins = 6)\n",
    "\n",
    "# Plot a historgram and kernel density estimate\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(8):\n",
    "    sns.distplot(sample[:,28+i], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax, alpha=0.6)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "_, ymax = ax.get_ylim()\n",
    "ax.vlines(data[\"dshift\"], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "ax.set_xlabel(r\"Emission/absorption line sign\")\n",
    "ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(datadir+froot+\"_signs.png\", format=\"png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A General Plotting function for the Posterior\n",
    "\n",
    "We'll make some individual plotting functions that we can then combine to plot useful Figures on the whole posterior sample!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_samples(data, sample, fout, close=True):\n",
    "    \"\"\"\n",
    "    FIRST PLOT: SPECTRUM + SAMPLES FROM THE POSTERIOR\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of posterior samples\n",
    "    nsamples = sample.shape[0]\n",
    "\n",
    "    # randomly pick some samples from the posterior to plot\n",
    "    s_ind = np.random.choice(np.arange(nsamples, dtype=int), size=20)\n",
    "\n",
    "    # the middle of the wavelength bins for plotting\n",
    "    wmid = data[\"wavelength_left\"] + (data[\"wavelength_right\"] - data[\"wavelength_left\"])/2.\n",
    "\n",
    "    # the error on the data\n",
    "    yerr = np.zeros_like(wmid) + data['err']\n",
    "\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.errorbar(wmid, data[\"fake_flux\"], yerr=yerr, fmt=\"o\")\n",
    "    for i in s_ind:\n",
    "        plt.plot(wmid, sample[i,-wmid.shape[0]:], lw=2, alpha=0.7)\n",
    "\n",
    "    plt.xlim(wmid[0], wmid[-1])\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xlabel(\"Wavelength [Angstrom]\")\n",
    "    plt.ylabel(\"Normalized Flux\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fout+\"_samples.png\", format=\"png\")\n",
    "    if close:\n",
    "        plt.close()\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_bkg(data, sample, fout, close=True):\n",
    "    \"\"\"\n",
    "    PLOT THE BACKGROUND POSTERIOR\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    # Plot a histogram and kernel density estimate\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.distplot(sample[:,0], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    _, ymax = ax.get_ylim()\n",
    "    ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax.set_xlabel(\"Normalized Background Flux\")\n",
    "    ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fout+\"_bkg.png\", format=\"png\")\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return\n",
    "    \n",
    "def plot_ou_bkg(sample, fout, close=True):\n",
    "    \"\"\"\n",
    "    PLOT THE POSTERIOR FOR THE OU PROCESS\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,6))\n",
    "    sns.distplot(sample[:,1], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax1)\n",
    "    #_, ymax = ax.get_ylim()\n",
    "    #ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax1.set_xlabel(r\"OU time scale $\\tau$\")\n",
    "    ax1.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "\n",
    "    sns.distplot(sample[:,2], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax2)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    #_, ymax = ax.get_ylim()\n",
    "    #ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax2.set_xlabel(r\"OU amplitude\")\n",
    "    ax2.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(fout+\"_ou.png\", format=\"png\")\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "def plot_logamp_hyper(data, sample, fout, close=True):\n",
    "    \"\"\"\n",
    "    PLOT THE POSTERIOR FOR THE LOG-AMP HYPERPARAMETERS\n",
    "    \"\"\"    \n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,6))\n",
    "    sns.distplot(np.log(sample[:,5]), hist_kws={\"histtype\":\"stepfilled\"}, ax=ax1)\n",
    "    _, ymax = ax1.get_ylim()\n",
    "    ax1.vlines(data[\"logamp\"], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax1.set_xlabel(r\"$\\mu_{\\mathrm{\\log{A}}}$\")\n",
    "    ax1.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "    ax1.set_title(\"Location parameter of the amplitude prior\")\n",
    "\n",
    "\n",
    "    sns.distplot(sample[:,6], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax2)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    #_, ymax = ax.get_ylim()\n",
    "    #ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax2.set_xlabel(r\"$\\sigma_{\\mathrm{\\log{A}}}$\")\n",
    "    ax2.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "    ax2.set_title(\"Scale parameter of the amplitude prior\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(fout+\"_logamp_prior.png\", format=\"png\")\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "def plot_logq_hyper(data, sample, fout, close=True):\n",
    "    \"\"\"\n",
    "    PLOT THE POSTERIOR FOR THE LOG-Q HYPERPARAMETERS\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,6))\n",
    "    sns.distplot(sample[:,7], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax1)\n",
    "    _, ymax = ax1.get_ylim()\n",
    "    ax1.vlines(data[\"logq\"], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax1.set_xlabel(r\"$\\mu_{\\mathrm{\\log{q}}}$\")\n",
    "    ax1.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "    ax1.set_title(r\"Location parameter of the $q$ prior\")\n",
    "\n",
    "\n",
    "    sns.distplot(sample[:,8], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax2)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    #_, ymax = ax.get_ylim()\n",
    "    #ax.vlines(np.exp(data[\"logbkg\"]), 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax2.set_xlabel(r\"$\\sigma_{\\mathrm{\\log{q}}}$\")\n",
    "    ax2.set_ylabel(r\"$N_{\\mathrm{samples}}$\")\n",
    "    ax2.set_title(r\"Scale parameter of the $q$ prior\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(fout+\"_logq_prior.png\", format=\"png\")\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "def plot_threshold(sample, fout, close=True):\n",
    "    \"\"\"\n",
    "    PLOT THE POSTERIOR FOR THE THRESHOLD PARAMETER\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    # Plot a historgram and kernel density estimate\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.distplot(sample[:,9], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    ax.set_xlabel(\"Threshold parameter\")\n",
    "    ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(fout+\"_pp.png\", format=\"png\")\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "def plot_dshift(data, sample, fout, dshift_ind=0, close=True):\n",
    "    \"\"\" \n",
    "    PLOT THE POSTERIOR FOR THE DOPPLER SHIFT\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    plt.locator_params(axis = 'x', nbins = 6)\n",
    "\n",
    "    # Plot a historgram and kernel density estimate\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.distplot(sample[:,11+dshift_ind], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "    _, ymax = ax.get_ylim()\n",
    "    ax.vlines(data[\"dshift\"], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "    ax.set_xlabel(r\"Doppler shift $d=v/c$\")\n",
    "    ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(fout+\"_dshift%i.png\"%dshift_ind, format=\"png\")\n",
    "    if close:\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "def plot_logamp(data, sample, fout, ndshift, nlines, ncolumns=3, \n",
    "                dshift_ind=0, close=True):\n",
    "    \"\"\"\n",
    "    PLOT THE POSTERIOR FOR THE LINE LOG-AMPLITUDES\n",
    "    \"\"\"\n",
    "    \n",
    "    nrows = int(nlines/ncolumns)+1\n",
    "\n",
    "    fig = plt.figure(figsize=(nrows*4,ncolumns*4))\n",
    "    plt.locator_params(axis = 'x', nbins = 6)\n",
    "\n",
    "    # index of column where the log-amplitudes start:\n",
    "    start_ind = 11 + ndshift + dshift_ind*nlines\n",
    "    \n",
    "    # log-amplitudes\n",
    "    for i in range(nlines):\n",
    "        ax = plt.subplot(nrows, ncolumns, i+1)    \n",
    "#        ax.hist(sample[:,start_ind+i], histtype=\"stepfilled\", alpha=0.7)\n",
    "        sns.distplot(sample[:,start_ind+i], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "\n",
    "        plt.locator_params(axis = 'x', nbins = 6)\n",
    "        xlabels = ax.get_xticklabels() \n",
    "        for l in xlabels: \n",
    "            l.set_rotation(45) \n",
    "\n",
    "        _, ymax = ax.get_ylim()\n",
    "        ax.vlines(data[\"logamp\"][i], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "        ax.set_xlabel(r\"$\\log{A}$\")\n",
    "        ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if dshift_ind == 0:\n",
    "        plt.savefig(fout+\"_logamp.png\", format=\"png\")\n",
    "    else:\n",
    "        plt.savefig(fout+\"_logamp%i.png\"%dshift_ind, format=\"png\")\n",
    "\n",
    "    if close:\n",
    "        plt.close()\n",
    "    \n",
    "    return\n",
    "\n",
    "def plot_logq(data, sample, fout, ndshift, nlines, ncolumns=3, \n",
    "              dshift_ind=0, close=True):\n",
    "    \"\"\"\n",
    "    PLOT THE POSTERIOR FOR THE LINE LOG-Q\n",
    "    \"\"\"\n",
    "\n",
    "    nrows = int(nlines/ncolumns)+1\n",
    "\n",
    "    fig = plt.figure(figsize=(nrows*4,ncolumns*4))\n",
    "    plt.locator_params(axis = 'x', nbins = 6)\n",
    "\n",
    "    # set starting index for the logq values:\n",
    "    start_ind = 11 + ndshift + nlines*(dshift_ind + 1)\n",
    "    \n",
    "    # log-amplitudes\n",
    "    for i in range(nlines):\n",
    "        ax = plt.subplot(nrows, ncolumns, i+1)    \n",
    "        #ax.hist(sample[:,start_ind+i], histtype=\"stepfilled\", alpha=0.7)\n",
    "        sns.distplot(sample[:,start_ind+i], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "        \n",
    "        plt.locator_params(axis = 'x', nbins = 6)\n",
    "        xlabels = ax.get_xticklabels() \n",
    "        for l in xlabels: \n",
    "            l.set_rotation(45) \n",
    "\n",
    "        _, ymax = ax.get_ylim()\n",
    "        ax.vlines(data[\"logq\"][i], 0, ymax, lw=3, color=\"black\")\n",
    "\n",
    "        ax.set_xlabel(r\"$\\log{q}$\")\n",
    "        ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if dshift_ind == 0:\n",
    "        plt.savefig(fout+\"_logq.png\", format=\"png\")\n",
    "    else:\n",
    "        plt.savefig(fout+\"_logq%i.png\"%dshift_ind, format=\"png\")\n",
    "    \n",
    "    if close:\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_signs(data, sample, fout, ndshift, nlines, ncolumns=3, \n",
    "               dshift_ind=0, close=True):\n",
    "    \"\"\"\n",
    "    PLOT THE POSTERIOR FOR THE LINE AMPLITUDE SIGNS\n",
    "    \"\"\"\n",
    "\n",
    "    nrows = int(nlines/ncolumns)+1\n",
    "    \n",
    "    fig = plt.figure(figsize=(nrows*4,ncolumns*4))\n",
    "    plt.locator_params(axis = 'x', nbins = 6)\n",
    "\n",
    "    # set starting index for the logq values:\n",
    "    start_ind = 11 + ndshift + nlines*(dshift_ind + 2)\n",
    "    \n",
    "    # log-amplitudes\n",
    "    for i in range(nlines):\n",
    "        ax = plt.subplot(nrows, ncolumns, i+1)    \n",
    "#        ax.hist(sample[:,start_ind+i], histtype=\"stepfilled\", alpha=0.7)\n",
    "        sns.distplot(sample[:,start_ind+i], hist_kws={\"histtype\":\"stepfilled\"}, ax=ax)\n",
    "\n",
    "        plt.locator_params(axis = 'x', nbins = 6)\n",
    "        xlabels = ax.get_xticklabels() \n",
    "        for l in xlabels: \n",
    "            l.set_rotation(45) \n",
    "\n",
    "        ax.set_xlabel(r\"Emission/absorption line sign\")\n",
    "        ax.set_ylabel(\"$N_{\\mathrm{samples}}$\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if dshift_ind == 0:\n",
    "        plt.savefig(fout+\"_signs.png\", format=\"png\")\n",
    "    else:\n",
    "        plt.savefig(fout+\"_signs%i.png\"%dshift_ind, format=\"png\")\n",
    "    \n",
    "    if close:\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_posterior_summary(froot, datadir=\"../data/\", nlines=8, \n",
    "                           ndshift=1, ncolumns=3, close=True):\n",
    "    \"\"\"\n",
    "    Plot summeries of the posterior distribution. Mostly histograms.\n",
    "    Plots a bunch of Figures to png files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    froot: str\n",
    "        The root string of the data file and file with posterior samples to be loaded.\n",
    "        \n",
    "    datadir: str\n",
    "        The directory with the data.\n",
    "        Default: \"../data/\"\n",
    "        \n",
    "    nlines: int\n",
    "        The number of lines in the model.\n",
    "        Default: 8\n",
    "        \n",
    "    ndshift: int\n",
    "        The number of (possible) Doppler shifts in the model.\n",
    "        Default: 1\n",
    "        \n",
    "    ncolumns: int\n",
    "        The number of columns in multi-panel plots. Default: 3\n",
    "    \n",
    "    close: bool\n",
    "        Close plots at the end of the plotting? Default: True\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # the pickle file with the data + parameters:\n",
    "    f = open(datadir+froot+\"_data.pkl\")\n",
    "    data = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    print(\"Keys in data dictionary: \" + str(data.keys()))\n",
    "\n",
    "    # the posterior samples\n",
    "    sample = np.atleast_2d(np.loadtxt(datadir+froot+\"_posterior_sample.txt\"))\n",
    "    nsamples = sample.shape[0]\n",
    "    print(\"We have %i samples from the posterior.\"%nsamples)\n",
    "    \n",
    "    # set the directory path and file name for output files:\n",
    "    fout = datadir+froot\n",
    "    \n",
    "    # plot the spectrum with some draws from the posterior\n",
    "    plot_samples(data, sample, fout, close=close)\n",
    "\n",
    "    # plot a histogram of the background parameter\n",
    "    plot_bkg(data, sample, fout, close=close)\n",
    "    \n",
    "    # plot histograms of the OU parameters\n",
    "    plot_ou_bkg(sample, fout, close=close)\n",
    "    \n",
    "    # plot the hyper parameters of the log-amp prior\n",
    "    plot_logamp_hyper(data, sample, fout, close=close)\n",
    "    \n",
    "    # plot the hyper parameters of the log-q prior\n",
    "    plot_logq_hyper(data, sample, fout, close=close)\n",
    "    \n",
    "    # plot the threshold for the amplitude sign\n",
    "    plot_threshold(sample, fout, close=close)\n",
    "    \n",
    "    # for the varying number of Doppler shifts, plot their posterior\n",
    "    if ndshift == 1:\n",
    "        plot_dshift(data, sample, fout, dshift_ind=0, close=close)\n",
    "        plot_logamp(data, sample, fout, ndshift, nlines, \n",
    "                    ncolumns=ncolumns, dshift_ind=0, close=close)\n",
    "        plot_logq(data, sample, fout, ndshift, nlines, \n",
    "                  ncolumns=ncolumns, dshift_ind=0, close=close)\n",
    "        plot_signs(data, sample, fout, ndshift, nlines, \n",
    "                   ncolumns=ncolumns, dshift_ind=0, close=close)        \n",
    "    else:\n",
    "        for i in range(ndshift):\n",
    "            plot_dshift(data, sample, fout, dshift_ind=i, close=close)\n",
    "            plot_logamp(data, sample, fout, ndshift, nlines, \n",
    "                        ncolumns=ncolumns, dshift_ind=i, close=close)\n",
    "            plot_logq(data, sample, fout, ndshift, nlines, \n",
    "                      ncolumns=ncolumns, dshift_ind=i, close=close)\n",
    "            plot_signs(data, sample, fout, ndshift, nlines, \n",
    "                       ncolumns=ncolumns, dshift_ind=i, close=close)        \n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this function on the data we just made individual plots from to see whether it worked.\n",
    "\n",
    "The model had $8$ lines and $1$ redshift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_posterior_summary(froot, datadir=\"../data/\", nlines=8, ndshift=1, ncolumns=3,\n",
    "                      close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A general function for simulating data sets\n",
    "\n",
    "Based on what we just did, we'll write a function that takes parameters as an input and spits out the files we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fake_data(wleft, wright, line_pos, input_pars, froot):\n",
    "    \"\"\"\n",
    "    Simulate spectra, including a (constant) background and a set of \n",
    "    (Gaussian) lines with given positions. \n",
    "    \n",
    "    The model integrates over wavelength/frequency/energy bins, hence \n",
    "    it requires the left and right bin edges rather than the centre of \n",
    "    the bin.\n",
    "    \n",
    "    Produces (1) a pickle file with the simulated data and parameters used\n",
    "    to produce the simulation; (2) an ASCII file that can be fed straight into \n",
    "    ShiftyLines; (3) a Figure of the simulated data and the model that \n",
    "    produced it.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wleft: numpy.ndarray\n",
    "        The left bin edges of the wavelength/frequency/energy bins\n",
    "        \n",
    "    wright: numpy.ndarray\n",
    "        The right bin edges of the wavelength/frequency/energy bins\n",
    "        \n",
    "    line_pos: numpy.ndarray\n",
    "        The positions of the spectral lines in the same units as \n",
    "        `wleft` and `wright`; will be translated into centroid\n",
    "        wavelength/frequency/energy of the Gaussian modelling the line\n",
    "        \n",
    "    input_pars: dict\n",
    "        A dictionary containing the following keywords (for detailed \n",
    "        descriptions see the docstring for `fake_spectrum`):\n",
    "            logbkg: the log-background\n",
    "            err: the error on the data points\n",
    "            dshift: the Doppler shift (just one!)\n",
    "            sample_logamp: sample the log-amplitudes?\n",
    "            sample_logq: sample the log-q values?\n",
    "            sample_signs: sample the amplitude signs (if no, all lines \n",
    "                          are absorption lines!)\n",
    "            logamp_mean: location of normal sampling distribution for log-amplitudes\n",
    "            logq_mean: location of normal sampling distribution for log-q\n",
    "            logamp_sigma: scale of normal sampling distribution for log-amplitudes\n",
    "            logq_sigma: scale of normal sampling distribution for log-q\n",
    "            nzero: Number of lines to set to zero\n",
    "\n",
    "    froot: str\n",
    "        A string describing the directory and file name of the output files\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # read out all the parameters\n",
    "    logbkg = input_pars[\"logbkg\"]\n",
    "    err = input_pars[\"err\"]\n",
    "    dshift = input_pars[\"dshift\"]\n",
    "    sample_logamp = input_pars[\"sample_logamp\"]\n",
    "    sample_logq = input_pars[\"sample_logq\"]\n",
    "    sample_signs = input_pars[\"sample_signs\"]\n",
    "    logamp_mean = input_pars[\"logamp_mean\"]\n",
    "    logq_mean = input_pars[\"logq_mean\"]\n",
    "    logamp_sigma = input_pars[\"logamp_sigma\"]\n",
    "    logq_sigma = input_pars[\"logq_sigma\"]\n",
    "    nzero = input_pars[\"nzero\"]\n",
    "\n",
    "    # simulate fake spectrum \n",
    "    pars = fake_spectrum(wleft, wright, line_pos, logbkg=logbkg, err=err, dshift=dshift, \n",
    "                         sample_logamp=sample_logamp, sample_logq=sample_logq, \n",
    "                         logamp_hypermean=logamp_mean, logq_hypermean=logq_mean, \n",
    "                         logamp_hypersigma=logamp_sigma, logq_hypersigma=logq_sigma,\n",
    "                         sample_signs=sample_signs, nzero=nzero)\n",
    "    \n",
    "    # read out model and fake flux, construct error\n",
    "    model_flux = pars[\"model_flux\"]\n",
    "    fake_flux = pars[\"fake_flux\"]\n",
    "    fake_err = np.zeros_like(fake_flux) + pars[\"err\"]\n",
    "    \n",
    "    # get the middle of each bin\n",
    "    wmid = wleft + (wright-wleft)/2.\n",
    "    \n",
    "    # plot the resulting data and model to a file\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.errorbar(wmid, fake_flux, yerr=fake_err, fmt=\"o\", label=\"simulated flux\", alpha=0.7)\n",
    "    plt.plot(wmid, model_flux, label=\"simulated model\", lw=3)\n",
    "    plt.xlim(wmid[0], wmid[-1])\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.legend(prop={\"size\":18})\n",
    "    plt.xlabel(\"Wavelength [Angstrom]\")\n",
    "    plt.ylabel(\"Normalized Flux\")\n",
    "    plt.savefig(froot+\"_lc.png\", format=\"png\")\n",
    "    \n",
    "    # save the whole dictionary in a pickle file\n",
    "    f = open(froot+\"_data.pkl\", \"w\")\n",
    "    pickle.dump(pars, f)\n",
    "    f.close()\n",
    "\n",
    "    # save the fake data in an ASCII file for input into ShiftyLines\n",
    "    np.savetxt(froot+\".txt\", np.array([wleft, wright, fake_flux, fake_err]).T)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Spectrum with Weak Absorption Lines\n",
    "\n",
    "The model should still work if the lines are very weak. We will simulate a spectrum with weak lines to test how the strength of the lines will affect the inferences drawn from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "froot = \"../data/test_noshift2\"\n",
    "\n",
    "input_pars = {}\n",
    "\n",
    "# set amplitude and q\n",
    "input_pars[\"logamp_mean\"] = np.log(0.1)\n",
    "input_pars[\"logq_mean\"] = np.log(600.)\n",
    "\n",
    "# set the width of the amplitude and q distribution (not used here)\n",
    "\n",
    "input_pars[\"logamp_sigma\"] =np.log(0.08)\n",
    "input_pars[\"logq_sigma\"] = np.log(50)\n",
    "\n",
    "# set Doppler shift\n",
    "input_pars[\"dshift\"] = 0.0\n",
    "\n",
    "# set background\n",
    "input_pars[\"logbkg\"] = np.log(0.09)\n",
    "\n",
    "# do not sample amplitudes or q-factors(all are the same!)\n",
    "input_pars[\"sample_logamp\"] = False\n",
    "input_pars[\"sample_logq\"] = False\n",
    "\n",
    "\n",
    "# lines are either absorption or emission lines this time!\n",
    "input_pars[\"sample_signs\"] = True\n",
    "\n",
    "# error on the data points (will sample from a Gaussian distribution)\n",
    "input_pars[\"err\"] = 0.007\n",
    "\n",
    "# do not set any lines to zero!\n",
    "input_pars[\"nzero\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake_data(wnew_left, wnew_right, si_all_val, input_pars, froot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we run DNest4 with $100$ levels.\n",
    "\n",
    "### Results\n",
    "\n",
    "Let's first move the samples into the right directory and give it the right filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "move_dnest_output(\"../data/%s\"%froot, \"../code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_posterior_summary(froot, datadir=\"../data/\", nlines=8, ndshift=1,\n",
    "                      ncolumns=3, close=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like for this spectrum the amplitude really is too weak to constrain anything, so the Doppler shift does whatever the hell it wants.\n",
    "\n",
    "I'm not sure I like this behaviour; I might need to ask Brendon about it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A Spectrum With Emission+Absorption Lines\n",
    "\n",
    "We'll do the same test as the first, but with varying strong emission and absorption lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "froot = \"../data/test_noshift3\"\n",
    "\n",
    "input_pars = {}\n",
    "\n",
    "# set amplitude and q\n",
    "input_pars[\"logamp_mean\"] = np.log(0.3)\n",
    "input_pars[\"logq_mean\"] = np.log(600.)\n",
    "\n",
    "# set the width of the amplitude and q distribution (not used here)\n",
    "\n",
    "input_pars[\"logamp_sigma\"] = np.log(0.08)\n",
    "input_pars[\"logq_sigma\"] = np.log(50)\n",
    "\n",
    "# set Doppler shift\n",
    "input_pars[\"dshift\"] = 0.0\n",
    "\n",
    "# set background\n",
    "input_pars[\"logbkg\"] = np.log(0.09)\n",
    "\n",
    "# do not sample amplitudes or q-factors(all are the same!)\n",
    "input_pars[\"sample_logamp\"] = False\n",
    "input_pars[\"sample_logq\"] = False\n",
    "\n",
    "\n",
    "# lines are either absorption or emission lines this time!\n",
    "input_pars[\"sample_signs\"] = True\n",
    "\n",
    "# error on the data points (will sample from a Gaussian distribution)\n",
    "input_pars[\"err\"] = 0.007\n",
    "\n",
    "# do not set any lines to zero!\n",
    "input_pars[\"nzero\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake_data(wnew_left, wnew_right, si_all_val, input_pars, froot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model the same as with `test_noshift2.txt`, but with $150$ levels.\n",
    "\n",
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move_dnest_output(froot, dnest_dir=\"../code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_posterior_summary(froot, datadir=\"../data/\", nlines=8, ndshift=1, ncolumns=3,\n",
    "                      close=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Spectrum With Variable Absorption Lines\n",
    "\n",
    "In this test, we'll see how the model deals with variable absorption lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "froot = \"../data/test_noshift4\"\n",
    "\n",
    "input_pars = {}\n",
    "\n",
    "# set amplitude and q\n",
    "input_pars[\"logamp_mean\"] = np.log(0.3)\n",
    "input_pars[\"logq_mean\"] = np.log(600.)\n",
    "\n",
    "# set the width of the amplitude and q distribution (not used here)\n",
    "\n",
    "input_pars[\"logamp_sigma\"] = 0.5\n",
    "input_pars[\"logq_sigma\"] = np.log(50)\n",
    "\n",
    "# set Doppler shift\n",
    "input_pars[\"dshift\"] = 0.0\n",
    "\n",
    "# set background\n",
    "input_pars[\"logbkg\"] = np.log(0.09)\n",
    "\n",
    "# sample amplitudes, but not q-factors(all are the same!)\n",
    "input_pars[\"sample_logamp\"] = True\n",
    "input_pars[\"sample_logq\"] = False\n",
    "\n",
    "\n",
    "# lines are either absorption or emission lines this time!\n",
    "input_pars[\"sample_signs\"] = False\n",
    "\n",
    "# error on the data points (will sample from a Gaussian distribution)\n",
    "input_pars[\"err\"] = 0.007\n",
    "\n",
    "# do not set any lines to zero!\n",
    "input_pars[\"nzero\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake_data(wnew_left, wnew_right, si_all_val, input_pars, froot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "I set the number of levels to $200$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move_dnest_output(froot, dnest_dir=\"../code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_posterior_summary(froot, datadir=\"../data/\", nlines=8, ndshift=1, ncolumns=3,\n",
    "                      close=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Spectrum with Lines Turned Off\n",
    "\n",
    "What does the model do if lines are just not there? This is an important question, \n",
    "so we will now make a spectrum with three lines having amplitudes $A=0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "froot = \"../data/test_noshift5\"\n",
    "\n",
    "input_pars = {}\n",
    "\n",
    "# set amplitude and q\n",
    "input_pars[\"logamp_mean\"] = np.log(0.3)\n",
    "input_pars[\"logq_mean\"] = np.log(600.)\n",
    "\n",
    "# set the width of the amplitude and q distribution (not used here)\n",
    "\n",
    "input_pars[\"logamp_sigma\"] = 0.5\n",
    "input_pars[\"logq_sigma\"] = np.log(50)\n",
    "\n",
    "# set Doppler shift\n",
    "input_pars[\"dshift\"] = 0.0\n",
    "\n",
    "# set background\n",
    "input_pars[\"logbkg\"] = np.log(0.09)\n",
    "\n",
    "# do not sample amplitudes or q-factors(all are the same!)\n",
    "input_pars[\"sample_logamp\"] = False\n",
    "input_pars[\"sample_logq\"] = False\n",
    "\n",
    "\n",
    "# lines are either absorption or emission lines this time!\n",
    "input_pars[\"sample_signs\"] = False\n",
    "\n",
    "# error on the data points (will sample from a Gaussian distribution)\n",
    "input_pars[\"err\"] = 0.007\n",
    "\n",
    "# Set three lines straight to zero!\n",
    "input_pars[\"nzero\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(20160221)\n",
    "fake_data(wnew_left, wnew_right, si_all_val, input_pars, froot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_posterior_summary(froot, datadir=\"../data/\", nlines=8, ndshift=1, ncolumns=3,\n",
    "                      close=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Doppler-shifted Spectrum with Absorption lines\n",
    "\n",
    "We are now going to look how well the model constrains the Doppler shift.\n",
    "Again, we build a simple model where all lines have the sample amplitude, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "froot = \"../data/test_shift1\"\n",
    "\n",
    "input_pars = {}\n",
    "\n",
    "# set amplitude and q\n",
    "input_pars[\"logamp_mean\"] = np.log(0.3)\n",
    "input_pars[\"logq_mean\"] = np.log(600.)\n",
    "\n",
    "# set the width of the amplitude and q distribution (not used here)\n",
    "\n",
    "input_pars[\"logamp_sigma\"] = 0.5\n",
    "input_pars[\"logq_sigma\"] = np.log(50)\n",
    "\n",
    "# set Doppler shift\n",
    "input_pars[\"dshift\"] = 0.01\n",
    "\n",
    "# set background\n",
    "input_pars[\"logbkg\"] = np.log(0.09)\n",
    "\n",
    "# do not sample amplitudes or q-factors(all are the same!)\n",
    "input_pars[\"sample_logamp\"] = False\n",
    "input_pars[\"sample_logq\"] = False\n",
    "\n",
    "\n",
    "# lines are only absorption lines this time!\n",
    "input_pars[\"sample_signs\"] = False\n",
    "\n",
    "# error on the data points (will sample from a Gaussian distribution)\n",
    "input_pars[\"err\"] = 0.007\n",
    "\n",
    "# Set three lines straight to zero!\n",
    "input_pars[\"nzero\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(20160220)\n",
    "fake_data(wnew_left, wnew_right, si_all_val, input_pars, froot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "move_dnest_output(froot, \"../code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_posterior_summary(froot, datadir=\"../data/\", nlines=8, ndshift=1, ncolumns=3,\n",
    "                      close=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Shifted Spectrum with Emission/Absorption Lines with Variable Amplitudes and Signs\n",
    "\n",
    "More complicated: a spectrum with a single Doppler shift and variable line amplitudes of both emission and absorption lines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "froot = \"../data/test_shift2\"\n",
    "\n",
    "input_pars = {}\n",
    "\n",
    "# set amplitude and q\n",
    "input_pars[\"logamp_mean\"] = np.log(0.3)\n",
    "input_pars[\"logq_mean\"] = np.log(600.)\n",
    "\n",
    "# set the width of the amplitude and q distribution (not used here)\n",
    "\n",
    "input_pars[\"logamp_sigma\"] = 0.5\n",
    "input_pars[\"logq_sigma\"] = np.log(50)\n",
    "\n",
    "# set Doppler shift\n",
    "input_pars[\"dshift\"] = 0.01\n",
    "\n",
    "# set background\n",
    "input_pars[\"logbkg\"] = np.log(0.09)\n",
    "\n",
    "# do not sample amplitudes or q-factors(all are the same!)\n",
    "input_pars[\"sample_logamp\"] = True\n",
    "input_pars[\"sample_logq\"] = False\n",
    "\n",
    "\n",
    "# lines are only absorption lines this time!\n",
    "input_pars[\"sample_signs\"] = True\n",
    "\n",
    "# error on the data points (will sample from a Gaussian distribution)\n",
    "input_pars[\"err\"] = 0.007\n",
    "\n",
    "# Set three lines straight to zero!\n",
    "input_pars[\"nzero\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(20160221)\n",
    "fake_data(wnew_left, wnew_right, si_all_val, input_pars, froot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Noise Process\n",
    "\n",
    "At this point, I should be adding an OU process to the data generation process to simulate the effect of a variable background in the spectrum.\n",
    "\n",
    "THIS IS STILL TO BE DONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Multiple Doppler Shift Components\n",
    "\n",
    "For all of the above simulations, we also ought to test how well the model works if I add additional Doppler shift components to sample over. \n",
    "\n",
    "For this, you'll need to change the line\n",
    "    \n",
    "    :dopplershift(3*nlines+1, 1, true, MyConditionalPrior())\n",
    "\n",
    "in `MyModel.cpp` to read\n",
    "\n",
    "    :dopplershift(3*nlines+1, 3, false, MyConditionalPrior())\n",
    "\n",
    "and recompile.\n",
    "This will sample over up to three different Doppler shifts at the same time. In theory, we expect that the posterior will have a strong mode at either zero Doppler shifts (for the non-Doppler-shifted data) or at $1$ for all types of data set (where for some, the Doppler shift is rather strongly constrained to $0$). \n",
    "\n",
    "\n",
    "### Results\n",
    "\n",
    "A place holder for the results from this experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The extended Spectrum: More lines!\n",
    "\n",
    "Let's also make some simulations for the extended spectrum with more lines. This will require the `extended_lines.txt` file. The file name for the file with the lines centroid is currently hard-coded in the `main.cpp` file. \n",
    "\n",
    "Change the line \n",
    "\n",
    "        Data::get_instance().load_lines(\"../data/si_lines.txt\");\n",
    "\n",
    "to\n",
    "\n",
    "        Data::get_instance().load_lines(\"../data/lines_extended.txt\");\n",
    "\n",
    "and also change the Doppler shifts in `MyModel.cpp` back to\n",
    "\n",
    "    :dopplershift(3*nlines+1, 1, true, MyConditionalPrior())\n",
    "    \n",
    "before recompiling. We will change the last line again in a little while, but first we'll test the general performance of the model on the extended data set.\n",
    "\n",
    "## An extended spectrum with variable line amplitudes and a single Doppler shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "froot = \"../data/test_extended_shift1\"\n",
    "\n",
    "input_pars = {}\n",
    "\n",
    "# set amplitude and q\n",
    "input_pars[\"logamp_mean\"] = np.log(0.2)\n",
    "input_pars[\"logq_mean\"] = np.log(600.)\n",
    "\n",
    "# set the width of the amplitude and q distribution (not used here)\n",
    "\n",
    "input_pars[\"logamp_sigma\"] = 0.4\n",
    "input_pars[\"logq_sigma\"] = np.log(50)\n",
    "\n",
    "# set Doppler shift\n",
    "input_pars[\"dshift\"] = 0.01\n",
    "\n",
    "# set background\n",
    "input_pars[\"logbkg\"] = np.log(0.09)\n",
    "\n",
    "# do not sample amplitudes or q-factors(all are the same!)\n",
    "input_pars[\"sample_logamp\"] = True\n",
    "input_pars[\"sample_logq\"] = False\n",
    "\n",
    "\n",
    "# lines are only absorption lines this time!\n",
    "input_pars[\"sample_signs\"] = True\n",
    "\n",
    "# error on the data points (will sample from a Gaussian distribution)\n",
    "input_pars[\"err\"] = 0.007\n",
    "\n",
    "# Set three lines straight to zero!\n",
    "input_pars[\"nzero\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(20162210)\n",
    "fake_data(wavelength_left, wavelength_right, lines_extended, input_pars, froot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Spectrum with Two Doppler Shifts\n",
    "\n",
    "What if the lines are shifted with respect to each other? \n",
    "\n",
    "Let's simulate a spectrum where the silicon lines are Doppler shifted by one value, but the other lines are shifted by a different Doppler shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "froot = \"test_extended_shift2\"\n",
    "\n",
    "# set amplitude and q\n",
    "logamp_mean = np.log(0.2)\n",
    "logq_mean = np.log(600.)\n",
    "\n",
    "# set the width of the amplitude and q distribution (not used here)\n",
    "\n",
    "logamp_sigma = 0.4\n",
    "logq_sigma = np.log(50)\n",
    "\n",
    "# set Doppler shift\n",
    "dshift1 = 0.01\n",
    "dshift2 = 0.02\n",
    "\n",
    "# set background\n",
    "logbkg1 = np.log(0.09)\n",
    "logbkg2 = -15.\n",
    "\n",
    "# do not sample amplitudes or q-factors(all are the same!)\n",
    "sample_logamp = True\n",
    "sample_logq = False\n",
    "\n",
    "# lines are only absorption lines this time!\n",
    "sample_signs = True\n",
    "\n",
    "# error on the data points (will sample from a Gaussian distribution)\n",
    "err = 0.007\n",
    "\n",
    "# Set three lines straight to zero!\n",
    "nzero = 0\n",
    "\n",
    "np.random.seed(20160201)\n",
    "pars1 = fake_spectrum(wavelength_left, wavelength_right, si_all_val, logbkg=logbkg1,\n",
    "                     dshift=dshift1, err=err, sample_logamp=sample_logamp, \n",
    "                     sample_logq=sample_logq, logamp_hypermean=logamp_mean, \n",
    "                     logamp_hypersigma=logamp_sigma, logq_hypermean=logq_mean,\n",
    "                     logq_hypersigma=logq_sigma, sample_signs=sample_signs, nzero=nzero)\n",
    "\n",
    "pars2 = fake_spectrum(wavelength_left, wavelength_right, other_lines_all_val, logbkg=logbkg2,\n",
    "                     dshift=dshift2, err=err, sample_logamp=sample_logamp, \n",
    "                     sample_logq=sample_logq, logamp_hypermean=logamp_mean, \n",
    "                     logamp_hypersigma=logamp_sigma, logq_hypermean=logq_mean,\n",
    "                     logq_hypersigma=logq_sigma, sample_signs=sample_signs, nzero=nzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_flux_c =  pars1[\"model_flux\"]+pars2[\"model_flux\"]\n",
    "fake_flux_c = model_flux_c + np.random.normal(0.0, err, size=model_flux_c.shape[0])\n",
    "fake_err_c = np.zeros_like(fake_flux_c) + pars1[\"err\"]\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.errorbar(wnew_mid, fake_flux, yerr=fake_err, fmt=\"o\", label=\"simulated flux\", alpha=0.7)\n",
    "plt.plot(wnew_mid, model_flux, label=\"simulated model\", lw=3)\n",
    "plt.xlim(wnew_mid[0], wnew_mid[-1])\n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend(prop={\"size\":18})\n",
    "plt.xlabel(\"Wavelength [Angstrom]\")\n",
    "plt.ylabel(\"Normalized Flux\")\n",
    "plt.savefig(datadir+froot+\"_lc.png\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save all the output files as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pars = {\"wavelength_left\": wavelength_left, \"wavelength_right\": wavelength_right, \"err\":err,\n",
    "        \"model_flux\": model_flux_c, \"fake_flux\": fake_flux_c,\n",
    "        \"dshift\": [dshift1, dshift2], \n",
    "        \"line_pos\": np.hstack([pars1[\"line_pos\"], pars2[\"line_pos\"]]), \n",
    "        \"logamp\": np.hstack([pars1[\"logamp\"], pars2[\"logamp\"]]),\n",
    "        \"signs\": np.hstack([pars1[\"signs\"], pars2[\"signs\"]]),\n",
    "        \"logq\":  np.hstack([pars1[\"logq\"], pars2[\"logq\"]]) }\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the whole dictionary in a pickle file\n",
    "f = open(froot+\"_data.pkl\", \"w\")\n",
    "pickle.dump(pars, f)\n",
    "f.close()\n",
    "\n",
    "# save the fake data in an ASCII file for input into ShiftyLines\n",
    "np.savetxt(froot+\".txt\", np.array([wavelength_left, wavelength_right, \n",
    "                                   fake_flux_c, fake_err_c]).T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple model for Doppler-shifted Spectra\n",
    "\n",
    "Below we define a basic toy model which samples over all the line amplitudes, widths as well as a Doppler shift. We'll later extend this to work in DNest4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logmin = -1.e16\n",
    "\n",
    "def gaussian_cdf(x, w0, width):\n",
    "    return 0.5*(1. + scipy.special.erf((x-w0)/(width*np.sqrt(2.))))\n",
    "\n",
    "def spectral_line(wleft, wright, w0, amplitude, width):\n",
    "    \"\"\"\n",
    "    Use the CDF of a Gaussian distribution to define spectral \n",
    "    lines. We use the CDF to integrate over the energy bins, \n",
    "    rather than taking the mid-bin energy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    wleft: array\n",
    "        Left edges of the energy bins\n",
    "        \n",
    "    wright: array\n",
    "        Right edges of the energy bins\n",
    "        \n",
    "    w0: float\n",
    "        The centroid of the line\n",
    "        \n",
    "    amplitude: float\n",
    "        The amplitude of the line\n",
    "        \n",
    "    width: float\n",
    "        The width of the line\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    line_flux: array\n",
    "        The array of line fluxes integrated over each bin\n",
    "    \"\"\"\n",
    "    line_flux = amplitude*(gaussian_cdf(wright, w0, width)-\n",
    "                           gaussian_cdf(wleft, w0, width))\n",
    "    return line_flux\n",
    "\n",
    "class LinePosterior(object):\n",
    "    def __init__(self, x_left, x_right, y, yerr, line_pos):\n",
    "        \"\"\"\n",
    "        A class to compute the posterior of all the lines in \n",
    "        a spectrum.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x_left: np.ndarray\n",
    "            The left edges of the independent variable (wavelength bins)\n",
    "        \n",
    "        x_right: np.ndarray\n",
    "            The right edges of the independent variable (wavelength bins)\n",
    "            \n",
    "        y: np.ndarray\n",
    "            The dependent variable (flux)\n",
    "            \n",
    "        yerr: np.ndarray\n",
    "            The uncertainty on the dependent variable (flux)\n",
    "            \n",
    "        line_pos: np.ndarray\n",
    "            The rest-frame positions of the spectral lines\n",
    "            \n",
    "        Attributes\n",
    "        ----------\n",
    "        x_left: np.ndarray\n",
    "            The left edges of the independent variable (wavelength bins)\n",
    "        \n",
    "        x_right: np.ndarray\n",
    "            The right edges of the independent variable (wavelength bins)\n",
    "          \n",
    "        x_mid: np.ndarray\n",
    "            The mid-bin positions\n",
    "            \n",
    "        y: np.ndarray\n",
    "            The dependent variable (flux)\n",
    "            \n",
    "        yerr: np.ndarray\n",
    "            The uncertainty on the dependent variable (flux)\n",
    "            \n",
    "        line_pos: np.ndarray\n",
    "            The rest-frame positions of the spectral lines\n",
    "\n",
    "        nlines: int\n",
    "            The number of lines in the model\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        self.x_left = x_left\n",
    "        self.x_right = x_right\n",
    "        self.x_mid = x_left + (x_right-x_left)/2.\n",
    "        \n",
    "        self.y = y\n",
    "        \n",
    "        assert np.size(yerr) == 1, \"Multiple errors are not supported!\"\n",
    "        \n",
    "        self.yerr = yerr\n",
    "        self.line_pos = line_pos\n",
    "        self.nlines = len(line_pos)\n",
    "        \n",
    "    def logprior(self, t0):\n",
    "        \"\"\"\n",
    "        The prior of the model. Currently there are Gaussian priors on the \n",
    "        line width as well as the amplitude and the redshift.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        t0: iterable\n",
    "            The list or array with the parameters of the model\n",
    "            Contains:\n",
    "                * Doppler shift\n",
    "                * a background parameter\n",
    "                * all line amplitudes\n",
    "                * all line widths\n",
    "\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        logp: float\n",
    "            The log-prior of the model\n",
    "        \n",
    "        \"\"\"\n",
    "        # t0 must have twice the number of lines (amplitude, width for each) plus a \n",
    "        # background plus the redshift\n",
    "        assert len(t0) == 2*self.nlines+2, \"Wrong number of parameters!\"\n",
    "        \n",
    "        # get out the individual parameters\n",
    "        dshift = t0[0] # Doppler shift\n",
    "        log_bkg = t0[1]\n",
    "        amps = t0[2:2+self.nlines]\n",
    "        log_widths = t0[2+self.nlines:]\n",
    "        \n",
    "        # prior on the Doppler shift is Gaussian\n",
    "        dshift_hypermean = 0.0\n",
    "        dshift_hypersigma = 0.01\n",
    "        \n",
    "        dshift_prior = scipy.stats.norm(dshift_hypermean, dshift_hypersigma)\n",
    "        p_dshift = np.log(dshift_prior.pdf(dshift))\n",
    "        \n",
    "        #print(\"p_dshift: \" + str(p_dshift))\n",
    "        \n",
    "        # Prior on the background is uniform\n",
    "        logbkg_min = -10.0\n",
    "        logbkg_max = 10.0\n",
    "        p_bkg = (log_bkg >= logbkg_min and log_bkg <= logbkg_max)/(logbkg_max-logbkg_min)\n",
    "        if p_bkg == 0:\n",
    "            p_logbkg = logmin\n",
    "        else:\n",
    "            p_logbkg = 0.0\n",
    "        \n",
    "        #print(\"p_logbkg: \" + str(p_logbkg))\n",
    "        \n",
    "        # prior on the amplitude is Gaussian\n",
    "        amp_hypermean = 0.0\n",
    "        amp_hypersigma = 0.1\n",
    "        \n",
    "        amp_prior = scipy.stats.norm(amp_hypermean, amp_hypersigma)\n",
    "        \n",
    "        p_amp = 0.0\n",
    "        for a in amps:\n",
    "            p_amp += np.log(amp_prior.pdf(a))\n",
    "        \n",
    "        #print(\"p_amp: \" + str(p_amp))\n",
    "        # prior on the log-widths is uniform:\n",
    "        logwidth_min = -5.\n",
    "        logwidth_max = 3.\n",
    "        \n",
    "        p_logwidths = 0.0\n",
    "        for w in log_widths:\n",
    "            #print(\"w: \" + str(w))\n",
    "            p_width = (w >= logwidth_min and w <= logwidth_max)/(logwidth_max-logwidth_min)\n",
    "            if p_width == 0.0:\n",
    "                p_logwidths += logmin\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        #print(\"p_logwidths: \" + str(p_logwidths))\n",
    "        logp = p_dshift + p_logbkg + p_amp + p_logwidths\n",
    "        \n",
    "        return logp\n",
    "    \n",
    "    @staticmethod\n",
    "    def _spectral_model(x_left, x_right, dshift, logbkg, line_pos, amplitudes, logwidths):\n",
    "        \"\"\"\n",
    "        The spectral model underlying the data. It uses the object \n",
    "        attributes `x_left` and `x_right` to integrate over the bins \n",
    "        correctly.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x_left: np.ndarray\n",
    "            The left bin edges of the ordinate (wavelength bins)\n",
    "            \n",
    "        x_right: np.ndarray\n",
    "            The right bin edges of the ordinate (wavelength bins)\n",
    "            \n",
    "        dshift: float\n",
    "            The Doppler shift\n",
    "            \n",
    "        logbkg: float\n",
    "            Logarithm of the constant background level\n",
    "        \n",
    "        line_pos: iterable\n",
    "            The rest frame positions of the line centroids in the same \n",
    "            units as `x_left` and `x_right`\n",
    "        \n",
    "        amplitudes: iterable\n",
    "            The list of all line amplitudes\n",
    "            \n",
    "        logwidths: iterable\n",
    "            The list of the logarithm of all line widths\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        flux: np.ndarray\n",
    "            The integrated flux in the bins defined by `x_left` and `x_right`\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        assert len(line_pos) == len(amplitudes), \"Line positions and amplitudes must have same length\"\n",
    "        assert len(line_pos) == len(logwidths), \"Line positions and widths must have same length\"\n",
    "        \n",
    "        # shift the line position by the redshift\n",
    "        line_pos_shifted = line_pos + dshift\n",
    "        \n",
    "        #print(line_pos_shifted)\n",
    "        # exponentiate logarithmic quantities\n",
    "        bkg = np.exp(logbkg)\n",
    "        widths = np.exp(logwidths)\n",
    "        \n",
    "        #print(widths)\n",
    "        # background flux\n",
    "        flux = np.zeros_like(x_left) + bkg\n",
    "\n",
    "        #print(amplitudes)\n",
    "        \n",
    "        # add all the line fluxes\n",
    "        for x0, a, w in zip(line_pos_shifted, amplitudes, widths):\n",
    "            flux += spectral_line(x_left, x_right, x0, a, w)\n",
    "\n",
    "        return flux\n",
    "\n",
    "        \n",
    "        \n",
    "    def loglikelihood(self, t0):\n",
    "        \"\"\"\n",
    "        The Gaussian likelihood of the model. \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        t0: iterable\n",
    "            The list or array with the parameters of the model\n",
    "            Contains:\n",
    "                * Doppler shift\n",
    "                * a background parameter\n",
    "                * all line amplitudes\n",
    "                * all line widths\n",
    "\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        loglike: float\n",
    "            The log-likelihood of the model\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        assert len(t0) == 2*self.nlines+2, \"Wrong number of parameters!\"\n",
    "        \n",
    "        # get out the individual parameters\n",
    "        dshift = t0[0] # Doppler shift\n",
    "        logbkg = t0[1]\n",
    "        amplitudes = t0[2:2+self.nlines]\n",
    "        logwidths = t0[2+self.nlines:]\n",
    "\n",
    "        model_flux = self._spectral_model(self.x_left, self.x_right, \n",
    "                                          dshift, logbkg, self.line_pos, \n",
    "                                          amplitudes, logwidths)\n",
    "\n",
    "        loglike = -(len(self.y)/2.)*np.log(2.*np.pi*self.yerr**2.) - \\\n",
    "                    np.sum((self.y-model_flux)**2./(2.*self.yerr**2.))\n",
    "            \n",
    "        return loglike\n",
    "    \n",
    "    def logposterior(self, t0):\n",
    "        \"\"\"\n",
    "        The Gaussian likelihood of the model. \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        t0: iterable\n",
    "            The list or array with the parameters of the model\n",
    "            Contains:\n",
    "                * Doppler shift\n",
    "                * a background parameter\n",
    "                * all line amplitudes\n",
    "                * all line widths\n",
    "\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        logpost: float\n",
    "            The log-likelihood of the model\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        # assert the number of input parameters is correct:\n",
    "        assert len(t0) == 2*self.nlines+2, \"Wrong number of parameters!\"\n",
    "\n",
    "        logpost = self.logprior(t0) + self.loglikelihood(t0)\n",
    "        #print(\"prior: \" + str(self.logprior(t0)))\n",
    "        #print(\"likelihood: \" + str(self.loglikelihood(t0)))\n",
    "        #print(\"posterior: \" + str(self.logposterior(t0)))\n",
    "        if np.isfinite(logpost):\n",
    "            return logpost\n",
    "        else:\n",
    "            return logmin\n",
    "\n",
    "    def __call__(self, t0):\n",
    "        return self.logposterior(t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `emcee` to sample. \n",
    "\n",
    "We're going to use one of our example data sets, one without Doppler shift and strong lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(datadir+\"test_spectra_noshift_sameamp_samewidth3.txt\")\n",
    "\n",
    "x_left = data[:,0]\n",
    "x_right = data[:,1]\n",
    "flux = data[:,3]\n",
    "f_err = 0.007\n",
    "\n",
    "lpost = LinePosterior(x_left, x_right, flux, f_err, si_all_val)\n",
    "\n",
    "plt.errorbar(lpost.x_mid, flux, yerr=f_err, fmt=\"o\", label=\"Fake data\")\n",
    "plt.plot(lpost.x_mid, data[:,4], label=\"Underlying model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_test = 0.0\n",
    "bkg_test = np.log(0.09)\n",
    "amp_test = np.zeros_like(si_all_val) - 0.5\n",
    "logwidth_test = np.log(np.zeros_like(si_all_val) + 0.01)\n",
    "\n",
    "p_test = np.hstack([d_test, bkg_test, amp_test, logwidth_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lpost.logprior(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_test = 0.0\n",
    "bkg_test = np.log(0.09)\n",
    "amp_test = np.zeros_like(si_all_val) - 0.5\n",
    "logwidth_test = np.log(np.zeros_like(si_all_val) + 0.01)\n",
    "\n",
    "p_test = np.hstack([d_test, bkg_test, amp_test, logwidth_test])\n",
    "\n",
    "lpost.loglikelihood(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nwalkers = 1000\n",
    "niter = 300\n",
    "burnin = 300\n",
    "\n",
    "# starting positions for all parameters, from the prior\n",
    "# the values are taken from the `logprior` method in `LinePosterior`.\n",
    "# If the hyperparameters of the prior change in there, they'd better \n",
    "# change here, too!\n",
    "dshift_start = np.random.normal(0.0, 0.01, size=nwalkers)\n",
    "logbkg_start = np.random.uniform(-10., 10., size=nwalkers)\n",
    "amp_start = np.random.normal(0.0, 0.1, size=(lpost.nlines, nwalkers))\n",
    "logwidth_start = np.random.uniform(-5., 3., size=(lpost.nlines, nwalkers))\n",
    "p0 = np.vstack([dshift_start, logbkg_start, amp_start, logwidth_start]).T\n",
    "\n",
    "ndim = p0.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lpost)\n",
    "pos, prob, state = sampler.run_mcmc(p0, burnin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler.reset()\n",
    "\n",
    "## do the actual MCMC run\n",
    "pos, prob, state = sampler.run_mcmc(pos, niter, rstate0=state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcall = sampler.flatchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(mcall.shape[1]):\n",
    "    pmean = np.mean(mcall[:,i])\n",
    "    pstd = np.std(mcall[:,i])\n",
    "    print(\"Parameter %i: %.4f +/- %.4f\"%(i, pmean, pstd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corner.corner(mcall);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lpost = LinePosterior(x_left, x_right, flux, f_err, si_all_val)\n",
    "\n",
    "plt.errorbar(lpost.x_mid, flux, yerr=f_err, fmt=\"o\", label=\"Fake data\")\n",
    "plt.plot(lpost.x_mid, data[:,4], label=\"Underlying model\")\n",
    "\n",
    "randind = np.random.choice(np.arange(mcall.shape[0]), replace=False, size=20)\n",
    "for ri in randind:\n",
    "    ri = int(ri)\n",
    "    p = mcall[ri]\n",
    "    dshift = p[0]\n",
    "    logbkg = p[1]\n",
    "    line_pos = lpost.line_pos\n",
    "    amplitudes = p[2:2+lpost.nlines]\n",
    "    logwidths = p[2+lpost.nlines:] \n",
    "    plt.plot(lpost.x_mid, lpost._spectral_model(x_left, x_right, dshift, logbkg, line_pos,\n",
    "                                               amplitudes, logwidths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to think about:\n",
    "* what if we don't have ten lines, but a hundred?\n",
    "* want to do actual inference on individual lines (i.e. want to know where they are)\n",
    "* how do we incorporate errors in the line positions?\n",
    "* should we do a straight model comparison for the redshifts?\n",
    "* how do we incorporate sections of data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
